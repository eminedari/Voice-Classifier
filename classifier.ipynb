{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Emine DarÄ±"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About The Challenge\n",
    "- In this challenge, the goal is to classify the audio records of professors of Turkish Academy using Machine Learning methods. Each record is approximately 5 seconds long. The dataset containing the records to train and test the models can be found on this [link](https://www.kaggle.com/c/turkishacademyvoicechallenge/overview) to the in-class competition published on Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import csv\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "* In this step, we first create a function to initialize a csv file to keep extracted features to use when train and test sets are processed. Saving the extracted features into a file instead of storing them in variables will save us time, as after we decide on the features we can go on to try different models with these saved files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file(filename,header,train=True):\n",
    "    file = open(filename, 'w', newline='')\n",
    "    with file:\n",
    "        writer = csv.writer(file)\n",
    "        #append the label to header only for the training stage\n",
    "        if train:\n",
    "            header.append(\"label\")\n",
    "        writer.writerow(header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we create a function that will be used to extract features using the [Librosa](https://librosa.org/doc/latest/feature.html#feature-extraction) library. This function will save the features in a file by appending them to the end the file for each audio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_save_features(audio_name, audio_path, file_to_save, train=True,label=0):\n",
    "\n",
    "        #Load the audio file\n",
    "        y, sr = librosa.load(audio_path, mono=True)\n",
    "        \n",
    "        #Extract features \n",
    "        rms = librosa.feature.rms(y=y)\n",
    "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        \n",
    "        #Append features in a list\n",
    "        extracted_features = f'{audio_name} {np.mean(chroma_stft)} {np.mean(rms)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n",
    "        for freq in mfcc:\n",
    "            extracted_features += f' {np.mean(freq)}'\n",
    "            \n",
    "        #Append label of the audio, if in train mode\n",
    "        if train:\n",
    "            extracted_features += f' {label}'    \n",
    "        \n",
    "        #Save the features in a file, in append mode\n",
    "        file = open(file_to_save, 'a', newline='')\n",
    "        with file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(extracted_features.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Last step of preparation is to write a function to normalize extracted features in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(dataset):\n",
    "    data_normalized = ((dataset-dataset.min())/(dataset.max()-dataset.min()))\n",
    "    return data_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "- As the next step we process the train set which is structured as:  _**train/train/class_id/**sample.wav_\n",
    "- The dataset is assumed to be saved in the same directory with the notebook/code.\n",
    "- **Warning:** _This step might take a **long time.**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count = 2\n",
    "\n",
    "#Create a list with names of the features to be extracted\n",
    "features = [\"filename\",\"rms\", \"chroma_stft\",\"spec_cent\", \"spec_bw\", \"rolloff\", \"zcr\"]\n",
    "for i in range(20):\n",
    "        features.append(\"mfcc_\" + str(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call the function to create the file to save the train set's features                 \n",
    "create_file('train_processed.csv',features)\n",
    "\n",
    "#Extract features for each audio in the train set    \n",
    "    \n",
    "for i in range(class_count):\n",
    "    for file in os.listdir(\"train/train/\" + str(i)):\n",
    "        file_path = \"train/train/\" + str(i) + \"/\" + file\n",
    "        extract_and_save_features(file, file_path,'train_processed.csv',True,i)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "- Now we process the test set that is structed as : _**test/test/**sample.wav_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call the function to create the file to save the test set's features \n",
    "create_file('test_processed.csv',features,train=False)\n",
    "\n",
    "#Extract features for each audio in the test set   \n",
    "for file in os.listdir(\"test/test\"):\n",
    "        file_path = \"test/test/\" + file\n",
    "        extract_and_save_features(file, file_path,'test_processed.csv',train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4\n",
    "- In the final step we pick a model and train it with the features we extracted. Then we predict the labels for the test set and write them into a file in submission format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction complete. Please check submission.csv file\n"
     ]
    }
   ],
   "source": [
    "#read the processed train data\n",
    "train_set = pd.read_csv(\"train_processed.csv\")\n",
    "\n",
    "#split x and y data, normalize x data\n",
    "x_train = normalize(train_set.drop([\"filename\",\"label\"],axis=1))\n",
    "y_train = train_set.label.values\n",
    "\n",
    "#choose a model and train it with the labels\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "#read the processed test data and drop the filename column, then normalize the dataset\n",
    "test_set = pd.read_csv(\"test_processed.csv\")\n",
    "x_test_norm = normalize( test_set.drop([\"filename\"],axis=1))\n",
    "\n",
    "#predict the test data with the model    \n",
    "predicted_data = model.predict(x_test_norm)\n",
    "\n",
    "\n",
    "#FileName,Class \n",
    "predicted_files = []\n",
    "for filename in os.listdir(\"test/test\"):\n",
    "    predicted_files.append(filename)\n",
    "    \n",
    "prediction = pd.DataFrame({\"FileName\" : predicted_files, \"Class\":predicted_data} )\n",
    "prediction.to_csv(\"submission.csv\", index = False, header=True)\n",
    "\n",
    "print(\"Prediction complete. Please check submission.csv file\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
